{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(os.path.realpath(\"__file__\")), \"pytorch_geometric_temporal\"))\n",
    "# https://stackoverflow.com/questions/35569042/ssl-certificate-verify-failed-with-python3\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting aiohttp (from torch_geometric)\n",
      "  Downloading aiohttp-3.10.10-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Collecting fsspec (from torch_geometric)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/myradeng/miniforge3/envs/temporal_env/lib/python3.10/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /Users/myradeng/miniforge3/envs/temporal_env/lib/python3.10/site-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/myradeng/miniforge3/envs/temporal_env/lib/python3.10/site-packages (from torch_geometric) (6.1.0)\n",
      "Requirement already satisfied: pyparsing in /Users/myradeng/miniforge3/envs/temporal_env/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /Users/myradeng/miniforge3/envs/temporal_env/lib/python3.10/site-packages (from torch_geometric) (2.32.3)\n",
      "Collecting tqdm (from torch_geometric)\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch_geometric)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch_geometric)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->torch_geometric)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->torch_geometric)\n",
      "  Downloading yarl-1.17.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (64 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->torch_geometric)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/myradeng/miniforge3/envs/temporal_env/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/myradeng/miniforge3/envs/temporal_env/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/myradeng/miniforge3/envs/temporal_env/lib/python3.10/site-packages (from requests->torch_geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/myradeng/miniforge3/envs/temporal_env/lib/python3.10/site-packages (from requests->torch_geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/myradeng/miniforge3/envs/temporal_env/lib/python3.10/site-packages (from requests->torch_geometric) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/myradeng/miniforge3/envs/temporal_env/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.11.0)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric)\n",
      "  Downloading propcache-0.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Downloading aiohttp-3.10.10-cp310-cp310-macosx_11_0_arm64.whl (390 kB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-macosx_11_0_arm64.whl (52 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading yarl-1.17.1-cp310-cp310-macosx_11_0_arm64.whl (91 kB)\n",
      "Downloading propcache-0.2.0-cp310-cp310-macosx_11_0_arm64.whl (45 kB)\n",
      "Installing collected packages: tqdm, propcache, multidict, fsspec, frozenlist, attrs, async-timeout, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch_geometric\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.5.1 requires sympy==1.13.1, but you have sympy 1.13.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 async-timeout-4.0.3 attrs-24.2.0 frozenlist-1.5.0 fsspec-2024.10.0 multidict-6.1.0 propcache-0.2.0 torch_geometric-2.6.1 tqdm-4.66.6 yarl-1.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_sparse\n",
      "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scipy (from torch_sparse)\n",
      "  Downloading scipy-1.14.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in /Users/myradeng/miniforge3/envs/temporal_env/lib/python3.10/site-packages (from scipy->torch_sparse) (1.26.4)\n",
      "Downloading scipy-1.14.1-cp310-cp310-macosx_12_0_arm64.whl (29.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.9/29.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: torch_sparse\n",
      "  Building wheel for torch_sparse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch_sparse: filename=torch_sparse-0.6.18-cp310-cp310-macosx_11_0_arm64.whl size=488911 sha256=7fd70217beac5145f727a90a6e2aad5d8cc2abf43f2a2801e247d7594f0ae821\n",
      "  Stored in directory: /Users/myradeng/Library/Caches/pip/wheels/c9/dd/0f/a6a16f9f3b0236733d257b4b4ea91b548b984a341ed3b8f38c\n",
      "Successfully built torch_sparse\n",
      "Installing collected packages: scipy, torch_sparse\n",
      "Successfully installed scipy-1.14.1 torch_sparse-0.6.18\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_scatter\n",
      "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: torch_scatter\n",
      "  Building wheel for torch_scatter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch_scatter: filename=torch_scatter-2.1.2-cp310-cp310-macosx_11_0_arm64.whl size=343606 sha256=fbf70105cf15b770197f16ca82a8e112df28657e55379da3fbba240a5b845c54\n",
      "  Stored in directory: /Users/myradeng/Library/Caches/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n",
      "Successfully built torch_scatter\n",
      "Installing collected packages: torch_scatter\n",
      "Successfully installed torch_scatter-2.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_geometric_temporal.torch_geometric_temporal.dataset import PemsBayDatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "--------------------------------------------------\n",
      "Number of nodes (traffic sensors): 325\n",
      "Number of node features: 2\n",
      "Number of timesteps in input: 12\n",
      "Number of timesteps in target: 12\n",
      "Number of edges in the graph: 2694\n"
     ]
    }
   ],
   "source": [
    "# Load in the data \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_geometric_temporal.torch_geometric_temporal.dataset import PemsBayDatasetLoader\n",
    "\n",
    "# Initialize the loader and load the dataset\n",
    "loader = PemsBayDatasetLoader()\n",
    "dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_geometric_temporal.torch_geometric_temporal.signal import temporal_signal_split\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch_geometric_temporal.torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x1750d5e40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = DCRNN(in_channels=node_features, out_channels=32, K=1)\n",
    "        self.linear = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x.flatten(start_dim=1), edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h\n",
    "        \n",
    "model = RecurrentGCN(node_features = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([325, 2, 12]) torch.Size([2, 2694]) torch.Size([2694]) torch.Size([325, 2, 12])\n"
     ]
    }
   ],
   "source": [
    "for time, snapshot in enumerate(test_dataset):\n",
    "    print(snapshot.x.shape, snapshot.edge_index.shape, snapshot.edge_attr.shape, snapshot.y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (325) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m time, snapshot \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataset):\n\u001b[1;32m     39\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m model(snapshot\u001b[38;5;241m.\u001b[39mx, snapshot\u001b[38;5;241m.\u001b[39medge_index, snapshot\u001b[38;5;241m.\u001b[39medge_attr)\n\u001b[0;32m---> 40\u001b[0m     cost \u001b[38;5;241m=\u001b[39m cost \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((\u001b[43my_hat\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43msnapshot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     41\u001b[0m cost \u001b[38;5;241m=\u001b[39m cost \u001b[38;5;241m/\u001b[39m (time\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     42\u001b[0m cost\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (325) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_geometric_temporal.torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "from pytorch_geometric_temporal.torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(iterable):\n",
    "        return iterable\n",
    "\n",
    "# Load and examine data\n",
    "loader = PemsBayDatasetLoader()\n",
    "dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
    "#train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = DCRNN(in_channels=node_features, out_channels=32, K=1)\n",
    "        self.linear = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x.flatten(start_dim=1), edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h\n",
    "        \n",
    "model = RecurrentGCN(node_features = 24)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(200)):\n",
    "    cost = 0\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "    cost = cost / (time+1)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "model.eval()\n",
    "cost = 0\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "cost = cost / (time+1)\n",
    "cost = cost.item()\n",
    "print(\"MSE: {:.4f}\".format(cost))\n",
    "\n",
    "# Evaluate\n",
    "# model.eval()\n",
    "# test_loss = 0\n",
    "# predictions = []\n",
    "# actuals = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch_x, batch_y in test_loader:\n",
    "#         # Forward pass\n",
    "#         y_hat = model(batch_x, test_edge_index, test_edge_attr)\n",
    "#         y_hat = y_hat.view(batch_y.shape)\n",
    "        \n",
    "#         # Compute loss\n",
    "#         loss = F.mse_loss(y_hat, batch_y)\n",
    "#         test_loss += loss.item()\n",
    "        \n",
    "#         predictions.append(y_hat)\n",
    "#         actuals.append(batch_y)\n",
    "\n",
    "# avg_test_loss = test_loss / len(test_loader)\n",
    "# print(f'\\nTest Loss: {avg_test_loss:.4f}')\n",
    "\n",
    "# # Plot predictions vs actuals for first test batch\n",
    "# def plot_predictions(pred, actual, sensor_idx=0):\n",
    "#     pred = pred[0, sensor_idx, 0, :].cpu().numpy()\n",
    "#     actual = actual[0, sensor_idx, 0, :].cpu().numpy()\n",
    "    \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(pred, 'r-', label='Predicted')\n",
    "#     plt.plot(actual, 'b-', label='Actual')\n",
    "#     plt.title(f'Predictions vs Actuals for Sensor {sensor_idx}')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "# # Plot results for first sensor\n",
    "# plot_predictions(predictions[0], actuals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_12_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
